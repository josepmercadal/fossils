{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120fdefc-8b02-4285-8b99-bd6105451ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import plot, utils, io\n",
    "import cellpose\n",
    "from scipy.ndimage import measurements\n",
    "import seaborn as sns\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d, Delaunay, ConvexHull\n",
    "from scipy.ndimage import center_of_mass\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "from itertools import *\n",
    "from pylab import *\n",
    "import time\n",
    "from collections import defaultdict, Counter\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "from shapely.geometry import LineString, MultiPolygon, MultiPoint, Point\n",
    "import collections\n",
    "from matplotlib.collections import LineCollection\n",
    "from collections import OrderedDict\n",
    "from scipy.ndimage import label\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as patches\n",
    "import networkx as nwx\n",
    "import math\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 9})\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'dejavusans'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0825e40-f3b8-45bf-8647-91cac8a30a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_neighbors(labeled_matrix):\n",
    "    neighbors = {label: set() for label in unique_labels if label != 0}\n",
    "\n",
    "    rows, cols = labeled_matrix.shape\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            current_label = labeled_matrix[i, j]\n",
    "            if current_label == 0:\n",
    "                continue\n",
    "\n",
    "            # Check 4-connected neighbors (up, down, left, right)\n",
    "            for di, dj in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "                ni, nj = i + di, j + dj\n",
    "                if 0 <= ni < rows and 0 <= nj < cols:\n",
    "                    neighbor_label = labeled_matrix[ni, nj]\n",
    "                    if neighbor_label != 0 and neighbor_label != current_label:\n",
    "                        neighbors[current_label].add(neighbor_label)\n",
    "\n",
    "    return neighbors\n",
    "\n",
    "def relabel_dataframe(labeled_image, dataframe):\n",
    "    # Initialize a new column for the new labels\n",
    "    new_labels = []\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        # Get the x and y positions of the centroid (assuming integers)\n",
    "        x, y = int(row['Center of the object_0']), int(row['Center of the object_1'])\n",
    "        \n",
    "        # Ensure x and y are within bounds of the labeled_image\n",
    "        if 0 <= x < labeled_image.shape[1] and 0 <= y < labeled_image.shape[0]:\n",
    "            # Get the label at the centroid position from labeled_image\n",
    "            label = labeled_image[y, x]\n",
    "        else:\n",
    "            label = -1  # Assign a default or error label if out of bounds\n",
    "        \n",
    "        # Append the label to the new list\n",
    "        new_labels.append(label)\n",
    "    \n",
    "    # Add the new labels as a column to the dataframe\n",
    "    dataframe['new_label'] = new_labels\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def compute_morans_I(neighbor_dict, dark_cells):\n",
    "\n",
    "    all_cells = set(neighbor_dict.keys()) | {n for neighbors in neighbor_dict.values() for n in neighbors}\n",
    "\n",
    "    # Assign values: dark cells = 1, light cells = 0\n",
    "    cell_values = {cell: 1 if cell in dark_cells else 0 for cell in all_cells}\n",
    "\n",
    "    # Compute mean cell value\n",
    "    x_values = np.array([cell_values[cell] for cell in all_cells])\n",
    "    x_mean = np.mean(x_values)\n",
    "\n",
    "    # Compute denominator (variance term)\n",
    "    denominator = np.sum((x_values - x_mean) ** 2)\n",
    "    if denominator == 0:\n",
    "        return np.nan  # Avoid division by zero\n",
    "\n",
    "    # Compute numerator and total weight sum W\n",
    "    numerator = 0\n",
    "    W = sum(len(neighbors) for neighbors in neighbor_dict.values())\n",
    "\n",
    "    for i in all_cells:\n",
    "        neighbors = neighbor_dict.get(i, set())  # Get neighbors or empty set if none\n",
    "        for j in neighbors:\n",
    "            if j in all_cells:\n",
    "                wij = 1  # Weight of neighbor connection\n",
    "                numerator += wij * (cell_values[i] - x_mean) * (cell_values[j] - x_mean)\n",
    "\n",
    "    # Compute Moran's I\n",
    "    moran_I = (len(all_cells) / W) * (numerator / denominator) if W > 0 else np.nan\n",
    "    return moran_I\n",
    "\n",
    "data = {}\n",
    "images = {}\n",
    "SIZES = {}\n",
    "DL = {}\n",
    "LL = {}\n",
    "Ncells = {}\n",
    "Ndark_cells = {}\n",
    "density_dark = {}\n",
    "ND = {}\n",
    "LSP = {}\n",
    "CSD = {}\n",
    "CS = {}\n",
    "NEIGHBORS = {}\n",
    "ANGLES = {}\n",
    "ORDER = {}\n",
    "MORAN = {}\n",
    "DARK_CENTROIDS = {}\n",
    "\n",
    "\n",
    "folders = ['thallus/sections']\n",
    "folder_paths = [Path(f) for f in folders]\n",
    "all_npy_paths = chain.from_iterable(folder.glob('*_seg.npy') for folder in folder_paths)\n",
    "\n",
    "k = -1;\n",
    "\n",
    "for npy_path in all_npy_paths:\n",
    "#for npy_path in all_npy_paths.glob('*_seg.npy'):\n",
    "    \n",
    "    k = k + 1\n",
    "\n",
    "    plt.figure(1,figsize = (10,10))\n",
    "    \n",
    "    img_path = npy_path.with_name(npy_path.stem[:-4] + '.jpg')\n",
    "    csv_path = npy_path.with_name(npy_path.stem[:-4] + '_table.csv')\n",
    "\n",
    "    if not csv_path.exists():\n",
    "        print(f\"Skipping {csv_path}, as it does not exist.\")\n",
    "        continue\n",
    "\n",
    "    dat = np.load(npy_path, allow_pickle=True).item()\n",
    "    dat_csv = pd.read_csv(csv_path, index_col = None)\n",
    "\n",
    "    if img_path.exists():\n",
    "        img = io.imread(img_path)\n",
    "        print(f\"Loaded {npy_path.name} and its associated image {img_path.name}\")\n",
    "    else:\n",
    "        print(f\"Warning: No associated image found for {npy_path.name}\")\n",
    "\n",
    "    size_threshold = 10\n",
    "\n",
    "    data[k] = dat\n",
    "    images[k] = img\n",
    "\n",
    "    labeled_image = data[k]['masks']\n",
    "    unique_labels = np.unique(labeled_image)\n",
    "\n",
    "    dat_csv = relabel_dataframe(labeled_image, dat_csv)\n",
    "    centroidss = {idx: (row['Center of the object_1'], row['Center of the object_0']) for idx, row in dat_csv.iterrows() }\n",
    "\n",
    "    dark_labels = np.array(dat_csv[(dat_csv['Predicted Class'].isin(['Oil body'])) & (dat_csv['Size in pixels'] > size_threshold)]['new_label'])\n",
    "    light_labels = np.array(dat_csv[(dat_csv['Predicted Class'].isin(['Epidermal'])) & (dat_csv['Size in pixels'] > size_threshold)]['new_label'])\n",
    "    ap_labels = np.array(dat_csv[(dat_csv['Predicted Class'].isin(['Air pore'])) & (dat_csv['Size in pixels'] > size_threshold)]['new_label'])\n",
    "\n",
    "    all_labels = np.array(dat_csv[(dat_csv['Size in pixels'] > size_threshold)]['new_label']) \n",
    "    #all_labels = np.array([int(k) for k in range(1,len(all_labels)+1)])\n",
    "\n",
    "    dat_csv = dat_csv[dat_csv['new_label'].isin(all_labels)]\n",
    "    centroidss = {idx: (row['Center of the object_1'], row['Center of the object_0']) for idx, row in dat_csv.iterrows() }\n",
    "\n",
    "    # plot image with masks overlaid\n",
    "    #mask_RGB = plot.mask_overlay(images[k], dat['masks'],\n",
    "    #                        colors=np.array(dat['colors']))\n",
    "\n",
    "    # plot image with outlines overlaid in red\n",
    "    outlines = utils.outlines_list(data[k]['masks'])\n",
    "\n",
    "    cmap = matplotlib.colors.ListedColormap(np.random.rand( 256,3))\n",
    "\n",
    "    plt.imshow(img, alpha = 1)\n",
    "    #plt.imshow(data[k]['masks'], alpha = 0.5, cmap = cmap)\n",
    "\n",
    "    #for o in outlines:\n",
    "        #plt.plot(o[:,0], o[:,1], color='red', linewidth = 1.)\n",
    "        \n",
    "    points = []\n",
    "    centroids = {}\n",
    "    sizes = {}\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        if label == 0:\n",
    "            continue  # Skip background or unlabeled areas\n",
    "        mask = labeled_image == label\n",
    "        centroid = center_of_mass(mask)\n",
    "        centroids[label] = centroid\n",
    "        size = sum(mask)\n",
    "        sizes[label] = size\n",
    "\n",
    "        # Calculate the average RGB values for the masked region\n",
    "    #    avg_color = np.mean(img[mask], axis=0)\n",
    "\n",
    "        # Determine if the cell is dark (average RGB values close to black)\n",
    "    #    if np.all(avg_color <= threshold):\n",
    "    #        dark_labels.append(label)\n",
    "    #    else:\n",
    "    #        light_labels.append(label)\n",
    "\n",
    "    #SIZES[k] = dat_csv['Size in pixels'].values\n",
    "    SIZES[k] = sizes\n",
    "\n",
    "    DL[k] = dark_labels    \n",
    "    LL[k] = light_labels    \n",
    "\n",
    "    dark_centroids = [centroids[j] for j in dark_labels if j in centroids]\n",
    "    DC = np.array(dark_centroids)\n",
    "        \n",
    "    #[plt.text(DC[:,1][i], DC[:,0][i], str(j), color='w', fontsize=7, ha='center', va='center') for i, j in enumerate(dark_labels)]\n",
    "    \n",
    "    Ncells[k] = len(dat_csv)\n",
    "    Ndark_cells[k] = len(dark_labels)\n",
    "    density_dark[k] = Ndark_cells[k]/Ncells[k]\n",
    "        \n",
    "    #plt.axis([2215,2382,1700,1800])\n",
    "\n",
    "    #0.1mm = 165pixels ---> 1mm = 1650pixels ---> 1pixel = 1/1650mm\n",
    "    \n",
    "    dark_cells = dark_labels\n",
    "    \n",
    "    neighbors = collections.OrderedDict(find_neighbors(labeled_image))\n",
    "    #neighbors = collections.OrderedDict((new_key, value) for new_key, (old_key, value) in enumerate(neighbors.items()))\n",
    "    \n",
    "    dark_cell_neighbors = defaultdict(set)\n",
    "    \n",
    "    for cell in dark_cells:\n",
    "        if cell in neighbors:\n",
    "            dark_cell_neighbors[cell] = neighbors[cell].intersection(dark_cells)\n",
    "    \n",
    "    # If you want to convert it to a regular dictionary (optional)\n",
    "    dark_cell_neighbors = dict(dark_cell_neighbors)\n",
    "    \n",
    "    # Function to perform DFS and find connected components\n",
    "    def dfs(cell, visited, component):\n",
    "        visited.add(cell)\n",
    "        component.add(cell)\n",
    "        for neighbor in dark_cell_neighbors[cell]:\n",
    "            if neighbor not in visited:\n",
    "                dfs(neighbor, visited, component)\n",
    "    \n",
    "    # Find all clusters\n",
    "    visited = set()\n",
    "    clusters = []\n",
    "    \n",
    "    for cell in dark_cells:\n",
    "        if cell not in visited:\n",
    "            component = set()\n",
    "            dfs(cell, visited, component)\n",
    "            clusters.append(component)\n",
    "\n",
    "    # Calculate the sizes of clusters\n",
    "    cluster_sizes = [len(cluster) for cluster in clusters]\n",
    "    cluster_sizes = Counter(cluster_sizes)\n",
    "    \n",
    "    def compute_gabriel_graph(points):\n",
    "        # Compute the Delaunay triangulation\n",
    "        delaunay = Delaunay(points)\n",
    "        edges = []\n",
    "    \n",
    "        # Iterate through the edges of the Delaunay triangulation\n",
    "        for simplex in delaunay.simplices:\n",
    "            for i in range(3):\n",
    "                for j in range(i + 1, 3):\n",
    "                    p1, p2 = points[simplex[i]], points[simplex[j]]\n",
    "                    mid_point = (p1 + p2) / 2\n",
    "                    radius = np.linalg.norm(p1 - p2) / 2  # Correct radius calculation (half the distance)\n",
    "    \n",
    "                    is_gabriel = True\n",
    "    \n",
    "                    # Check if any other point lies within the circle\n",
    "                    for k in range(len(points)):\n",
    "                        if k != simplex[i] and k != simplex[j]:  # Exclude points on the current edge\n",
    "                            if np.linalg.norm(points[k] - mid_point) < radius:\n",
    "                                is_gabriel = False\n",
    "                                break\n",
    "    \n",
    "                    if is_gabriel:\n",
    "                        edges.append((simplex[i], simplex[j]))\n",
    "    \n",
    "        return edges\n",
    "\n",
    "    ################\n",
    "    \n",
    "    points = np.array(list(centroids.values()))\n",
    "    \n",
    "    dark_points = DC\n",
    "\n",
    "    gabriel_dark = compute_gabriel_graph(dark_points)\n",
    "    \n",
    "    G_dark = nwx.Graph()\n",
    "    for point in dark_points:\n",
    "        G_dark.add_node(tuple(point))\n",
    "    G_dark.add_edges_from(gabriel_dark)\n",
    "    \n",
    "    G = nwx.Graph()\n",
    "    \n",
    "    for region, neighbors_set in neighbors.items():\n",
    "        G.add_node(region)  # Add the region as a node\n",
    "        for neighbor in neighbors_set:\n",
    "            G.add_edge(region, neighbor)  # Add an edge between the region and its neighbors\n",
    "    \n",
    "    def find_simplices_from_gabriel_graph(G):\n",
    "        cliques = list(nwx.find_cliques(G))\n",
    "        # Filter cliques to find simplices (size 3 or more)\n",
    "        simplices = [clique for clique in cliques if len(clique) >= 3]\n",
    "        return simplices\n",
    "        \n",
    "    def find_all_cliques(G):\n",
    "        # Find all cliques in the graph\n",
    "        cliques = list(nwx.find_cliques(G))\n",
    "        return cliques\n",
    "\n",
    "    #pos = {region: (x, y) for region, (y,x) in centroids.items()}\n",
    "    #nwx.draw_networkx(G, pos, node_color = 'k', edge_color = 'k', node_size = 15, width = 1.5, with_labels=False, alpha = 1)\n",
    "\n",
    "    #plt.plot(DC[:,1], DC[:,0], 'C0o', markersize = 7)  # centroids are plotted in red\n",
    "\n",
    "    #gabriel_dark_simplices = np.array(find_simplices_from_gabriel_graph(G_dark))\n",
    "    ###making np.array sometimes gives errors because it finds simplices of 4 elements instead of 3, and cannot convert to array\n",
    "    gabriel_dark_cliques = find_all_cliques(G_dark)\n",
    "    \n",
    "    gabriel_neighbors = {label: [] for label in dark_labels}\n",
    "    angles = []\n",
    "    \n",
    "    # Find neighbors from the Gabriel graph\n",
    "    for clique in gabriel_dark_cliques:\n",
    "        for i in range(len(clique)):\n",
    "            for j in range(len(clique)):\n",
    "                if i != j:\n",
    "                    p1 = dark_labels[clique[i]]\n",
    "                    p2 = dark_labels[clique[j]]\n",
    "                    gabriel_neighbors[p1].append(p2)\n",
    "\n",
    "        if len(clique) == 3:  # Ensure it's a triangle (this I have to check for the angles, as sometimes they are not triangles)\n",
    "            ppp = [centroids[dark_labels[point]] for point in clique]\n",
    "            \n",
    "            distances = squareform(pdist(ppp))\n",
    "            \n",
    "            a, b, c = distances[0, 1], distances[1, 2], distances[0, 2]\n",
    "            \n",
    "            angle_A = np.arccos((b**2 + c**2 - a**2) / (2 * b * c))\n",
    "            angle_B = np.arccos((a**2 + c**2 - b**2) / (2 * a * c))\n",
    "            angle_C = np.arccos((a**2 + b**2 - c**2) / (2 * a * b))\n",
    "            \n",
    "            angles.extend([angle_A, angle_B, angle_C])\n",
    "\n",
    "    all_gabriel_angles = np.degrees(angles)\n",
    "    \n",
    "    # Remove duplicates in neighbors\n",
    "    for key in gabriel_neighbors.keys():\n",
    "        gabriel_neighbors[key] = list(set(gabriel_neighbors[key]))\n",
    "    \n",
    "    def get_neighbors(label):\n",
    "        if label in gabriel_neighbors:\n",
    "            return gabriel_neighbors[label]\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    dark_neighbors = {label: get_neighbors(label) for label in dark_labels}\n",
    "    \n",
    "    #######\n",
    "    ###to compute neighbour density\n",
    "    def compute_avg_dark_neighbors(clusters, dark_cells, neiList):\n",
    "        dark_cells_set = set(dark_cells)  # Convert dark_cells to a set for fast lookup\n",
    "        cs = []\n",
    "        nd = []\n",
    "    \n",
    "        for cluster in clusters:\n",
    "            dark_neighbor_counts = []\n",
    "    \n",
    "            # Check if the cluster is a set or just an int\n",
    "            if isinstance(cluster, int):\n",
    "                cluster = {cluster}  # Convert single int to a set\n",
    "    \n",
    "            for cell in cluster:\n",
    "                NN = neiList.get(cell, set())  # Safely get neighbors\n",
    "                dark_neighbors = sum(1 for nei in NN if nei in dark_cells_set)\n",
    "                dark_neighbor_counts.append(dark_neighbors)\n",
    "    \n",
    "            avg_dark_neighbors = np.mean(dark_neighbor_counts) if dark_neighbor_counts else 0\n",
    "            cs.append(len(cluster))\n",
    "            nd.append(avg_dark_neighbors)\n",
    "    \n",
    "        return cs, nd\n",
    "    \n",
    "    cs, nd = compute_avg_dark_neighbors(clusters, dark_cells, neighbors)\n",
    "        \n",
    "    # Function to find the shortest path between two points\n",
    "    def find_shortest_path(G, start_point, end_point):\n",
    "        shortest_path = nwx.shortest_path(G, source=start_point, target=end_point, weight='weight')\n",
    "        return shortest_path\n",
    "    \n",
    "    all_pairs = set()\n",
    "    \n",
    "    for label in dark_labels:\n",
    "        for nei in dark_neighbors[label]:\n",
    "            pair = tuple(sorted((label, nei)))\n",
    "            all_pairs.add(pair)\n",
    "                    \n",
    "    len_shortest_path = np.zeros(len(all_pairs));\n",
    "\n",
    "    all_pairs = list(all_pairs)\n",
    "\n",
    "    for edge in gabriel_dark:\n",
    "        p1, p2 = edge\n",
    "        point1 = dark_points[p1]\n",
    "        point2 = dark_points[p2]\n",
    "        plt.plot([point1[1], point2[1]], [point1[0], point2[0]], 'C0o-', linewidth=2, marker='.', markersize = 5)\n",
    "     \n",
    "    kk = -1\n",
    "    angles = []\n",
    "\n",
    "    for l,j in all_pairs:\n",
    "        \n",
    "        kk = kk + 1\n",
    "    \n",
    "        start_label = l\n",
    "        end_label = j\n",
    "    \n",
    "        shortest_path = find_shortest_path(G, start_label, end_label)\n",
    "    \n",
    "        path_points = [centroids[k] for k in shortest_path]\n",
    "        path_points = np.asarray([list(elem) for elem in path_points])\n",
    "\n",
    "        plt.plot(path_points[:, 1], path_points[:, 0], color='r', linewidth=1.5, marker='.', markersize = 5, alpha = 1)\n",
    "\n",
    "        len_shortest_path[kk] = len(shortest_path)-1\n",
    "\n",
    "    cell_values = {cell: 1 for cell in dark_labels}\n",
    "    cell_values.update({cell: 0 for cell in light_labels})\n",
    "\n",
    "    missing_keys = {n for nn in neighbors.values() for n in nn} - set(cell_values.keys())\n",
    "\n",
    "    order_parameter = 0\n",
    "    for cell, nn in neighbors.items():\n",
    "        if cell not in cell_values:\n",
    "            continue  # Skip if the cell itself is missing\n",
    "    \n",
    "        valid_neighbors = [n for n in nn if n in cell_values]  # Only keep valid neighbors\n",
    "        if valid_neighbors:  # Ensure we have at least one valid neighbor\n",
    "            avg_diff = sum(abs(cell_values[cell] - cell_values[n]) for n in valid_neighbors) / len(valid_neighbors)\n",
    "            order_parameter += avg_diff\n",
    "    \n",
    "    order_parameter = order_parameter/len(cell_values)\n",
    "    moran_I = compute_morans_I(neighbors, dark_labels)\n",
    "        \n",
    "    ANGLES[k] = all_gabriel_angles\n",
    "    CS[k] = cs \n",
    "    CSD[k] = cluster_sizes \n",
    "    NEIGHBORS[k] = neighbors\n",
    "    ND[k] = nd\n",
    "    LSP[k] = len_shortest_path\n",
    "    ORDER[k] = order_parameter\n",
    "    MORAN[k] = moran_I\n",
    "    DARK_CENTROIDS[k] = DC\n",
    "\n",
    "    print(Ncells[k],Ndark_cells[k],density_dark[k])\n",
    "    #plt.savefig('image_network.pdf', transparent = True, bbox_inches='tight' )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701aa5d1-80c1-4115-b4b5-f5d42e855c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_angles = [value for array in ANGLES.values() for value in array]\n",
    "combined_angles =  np.radians(combined_angles)\n",
    "\n",
    "print(density_dark)\n",
    "print(Ncells)\n",
    "\n",
    "print('Average number of oil body cells:',np.mean(list(Ndark_cells.values())),'Â±',np.std(list(Ndark_cells.values())))\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'}, figsize = (3,3))\n",
    "\n",
    "num_bins = 30\n",
    "\n",
    "counts, bins, patches = ax.hist(combined_angles, bins=num_bins, density=True, edgecolor='black', linewidth = 0.8)\n",
    "\n",
    "norm_angles = (bins[:-1] + bins[1:]) / 2  # Midpoint of each bin\n",
    "norm_angles = np.degrees(norm_angles)  # Convert to degrees for the colormap\n",
    "norm_angles = norm_angles / 120.0  # Normalize to [0, 1] for the colormap\n",
    "\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"white\",\"burlywood\",\"saddlebrown\",\"saddlebrown\"])\n",
    "\n",
    "for angle, patch in zip(norm_angles, patches):\n",
    "    color = cmap(angle)\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "ax.set_theta_direction(1)  # Clockwise direction\n",
    "ax.set_theta_offset(0)  # Start at 0 degrees on the right\n",
    "\n",
    "ax.set_thetamin(0); ax.set_thetamax(120)\n",
    "\n",
    "ax.set_xticks([0,np.pi/6,np.pi/3,np.pi/2,2*np.pi/3])\n",
    "ax.set_yticks([])\n",
    "\n",
    "\n",
    "ax.grid(linewidth = 1, alpha = 0.4)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=0, vmax=120))\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax, orientation='horizontal', label='angle', shrink = 0.9, ticks=[0,40,80,120], pad = -0.05)\n",
    "\n",
    "plt.savefig('histogram_angles.pdf', transparent = True, bbox_inches='tight' )\n",
    "plt.savefig('histogram_angles.svg')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#############\n",
    "\n",
    "\n",
    "fig, (ax0,ax1,ax2,ax3) = plt.subplots(1, 4, figsize=(13,2), width_ratios=[0.7,2,2,2])\n",
    "fig.subplots_adjust(wspace=0.35)\n",
    "\n",
    "ddd = [list(density_dark.values()),list(density_dark.values())]\n",
    "\n",
    "sns.boxplot(ddd, widths = 0.5, palette = ['y','y'], ax = ax0, linewidth = 1.2)\n",
    "sns.stripplot(data=ddd, ax=ax0, marker = 'o', color='w', edgecolor = 'k', jitter = True, linewidth=0.7,size=2.3, alpha = 0.7)\n",
    "\n",
    "ax0.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "ax0.set_ylim(0.,0.06)\n",
    "ax0.set_xlim(-0.6,0.6)\n",
    "\n",
    "ax0.set_ylabel(r'dark cell density $\\rho$')\n",
    "ax0.set_xticklabels(['exp.'])\n",
    "\n",
    "\n",
    "########################\n",
    "\n",
    "density_av = np.mean(list(density_dark.values()))\n",
    "density_std = np.std(list(density_dark.values()))\n",
    "\n",
    "lsp_together = np.concatenate(list(LSP.values()))\n",
    "csd_together = defaultdict(int)\n",
    "\n",
    "lspt = collections.OrderedDict(sorted(Counter(lsp_together).items()))\n",
    "\n",
    "for sub_dict in CSD.values():\n",
    "    for key, value in sub_dict.items():\n",
    "        csd_together[key] += value\n",
    "\n",
    "csd_together = dict(collections.OrderedDict(sorted(csd_together.items())))\n",
    "\n",
    "all_bins = set()\n",
    "for values in LSP.values():\n",
    "    all_bins.update(values)\n",
    "\n",
    "all_bins = sorted(all_bins)\n",
    "\n",
    "histograms = []\n",
    "\n",
    "for values in LSP.values():\n",
    "    histogram = Counter(values)\n",
    "    histogram_values = list(histogram.values())\n",
    "    total = sum(histogram_values)\n",
    "    \n",
    "    #print(\"Histogram values:\", histogram_values)\n",
    "    #print(\"Total:\", total)\n",
    "    \n",
    "    if total > 0:\n",
    "        histogram_normalized = {k: v / total for k, v in histogram.items()}\n",
    "    else:\n",
    "        histogram_normalized = {}\n",
    "    \n",
    "    histogram_values = [histogram_normalized.get(bin_key, 0) for bin_key in all_bins]\n",
    "    histograms.append(histogram_values)\n",
    "\n",
    "histograms_array = np.array(histograms)\n",
    "\n",
    "mean_histogram = np.mean(histograms_array, axis=0)\n",
    "std_histogram = np.std(histograms_array, axis=0)\n",
    "\n",
    "ax1.bar(all_bins, mean_histogram, yerr=std_histogram, capsize=3, color='y', alpha=0.8, width=1, edgecolor='k', align='center')\n",
    "#ax1.plot(all_bins, mean_histogram, 'wo', alpha=0.8, ms=4, markeredgecolor='k')\n",
    "\n",
    "ax1.set_xlabel('cells apart')\n",
    "ax1.set_ylabel('frequency')\n",
    "#ax1.grid(alpha = 0.2, linewidth = 1.);\n",
    "ax1.set_xticks([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]);\n",
    "ax1.set_xticklabels(['0', '1', '2', '3', '4', '5', '6', '7','8', '9', '10', '', '', '', '', '', '', '','','20'])\n",
    "\n",
    "ax1.set_xlim(0.5,11.5)\n",
    "ax1.set_ylim(0,1)\n",
    "#ax1.legend(loc = 'upper right', fontsize = 12)\n",
    "\n",
    "ax1.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "#ax1.annotate(r'$\\langle \\rho \\rangle = %.2f \\pm %.2f$'%(density_av,density_std),[5.5,0.2], fontsize = 10)\n",
    "\n",
    "# Add inset for slope\n",
    "inset_ax = ax1.inset_axes([0.51, 0.5, 0.47, 0.47])\n",
    "\n",
    "#inset_ax.plot(all_bins, mean_histogram, 'wo', alpha=0.8, ms=4, markeredgecolor='k')\n",
    "inset_ax.errorbar(all_bins, mean_histogram, yerr=std_histogram, capsize=2, fmt='o-', ecolor='k', linewidth=1, elinewidth=1, \n",
    "                  ms=3, color = 'y', markeredgecolor='k', markeredgewidth=0.7)\n",
    "\n",
    "###this is to plot all the data together, without averaging and errors\n",
    "#inset_ax.plot(list(lspt.keys()), list(lspt.values())/sum(list(lspt.values())), 'go-')\n",
    "\n",
    "\n",
    "inset_ax.set_yscale('log')\n",
    "inset_ax.set_xscale('log')\n",
    "inset_ax.grid(alpha = 0.2, linewidth = 1.);\n",
    "inset_ax.set_xticks([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]);\n",
    "inset_ax.set_xticklabels(['1', '', '', '', '5', '', '', '','', '10', '', '', '', '', '', '', '', '','','20'], fontsize = 9)\n",
    "inset_ax.set_yticks([0.000001,0.00001,0.0001,0.001,0.01,0.1,1,2]);\n",
    "inset_ax.set_yticklabels(['$10^{-6}$', '','', '$10^{-3}$', '', '', '$10^{0}$', ''], fontsize = 9)\n",
    "\n",
    "\n",
    "csd = list(csd_together.values())/sum(list(csd_together.values()))\n",
    "cskey = list(csd_together.keys())\n",
    "\n",
    "ax2.bar(cskey, csd,  color='y', alpha=0.8, width=1, edgecolor='k', align='center')\n",
    "#ax2.plot(cskey, csd, 'wo-', alpha=0.8, ms=4, markeredgecolor='k')\n",
    "\n",
    "ax2.set_xlabel('cluster size')\n",
    "ax2.set_ylabel('frequency')\n",
    "#ax2.grid(alpha = 0.2, linewidth = 1.);\n",
    "ax2.set_xticks([1,2,3,4,5,6,7,8,9,10]);\n",
    "ax2.set_xticklabels(['1', '2', '3', '4', '5', '6', '7','8', '9','10'])\n",
    "\n",
    "ax2.set_xlim(0.5,10.5)\n",
    "ax2.set_ylim(0,1)\n",
    "#ax2.legend(loc = 'upper right', fontsize = 12)\n",
    "\n",
    "ax2.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "# Add inset for slope\n",
    "inset_ax = ax2.inset_axes([0.45, 0.5, 0.4, 0.47])\n",
    "\n",
    "#inset_ax.plot(all_bins, mean_histogram, 'wo', alpha=0.8, ms=4, markeredgecolor='k')\n",
    "inset_ax.errorbar(cskey, csd, capsize=2, fmt='o-', ecolor='k', linewidth=1, elinewidth=1, \n",
    "                  ms=3, color = 'y', markeredgecolor='k', markeredgewidth=0.7)\n",
    "#inset_ax.plot(all_bins, mean_histogram, 'k-', alpha=0.8, ms=4, markeredgecolor='k')\n",
    "\n",
    "inset_ax.set_xlim([1,20])\n",
    "\n",
    "inset_ax.set_yscale('log')\n",
    "inset_ax.set_xscale('log')\n",
    "inset_ax.grid(alpha = 0.2, linewidth = 1.);\n",
    "inset_ax.set_xticks([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]);\n",
    "inset_ax.set_xticklabels(['1', '', '', '', '', '', '', '','', '10','','','','','','','','','','20'], fontsize = 9)\n",
    "inset_ax.set_yticks([0.000001,0.00001,0.0001,0.001,0.01,0.1,1,2]);\n",
    "inset_ax.set_yticklabels(['$10^{-6}$','','', '$10^{-3}$', '', '', '$10^{0}$', ''], fontsize = 9)\n",
    "\n",
    "\n",
    "######################################\n",
    "\n",
    "size_density_data = defaultdict(list)\n",
    "\n",
    "for sim in ND.keys():\n",
    "    cluster_sizes = CS[sim]\n",
    "    densities = ND[sim]\n",
    "\n",
    "    for size, density in zip(cluster_sizes, densities):\n",
    "        if size == 1:\n",
    "            size_density_data[size].append(0.0)\n",
    "        else:\n",
    "            size_density_data[size].append(density)\n",
    "            \n",
    "\n",
    "for sim in CS.keys():\n",
    "    for size, density in zip(CS[sim], ND[sim]):\n",
    "        size_density_data[size].append(density)\n",
    "\n",
    "cluster_sizes = np.array(sorted(size_density_data.keys()))\n",
    "mean_densities = np.array([np.mean(size_density_data[size]) for size in cluster_sizes])\n",
    "std_densities = np.array([np.std(size_density_data[size]) for size in cluster_sizes])\n",
    "\n",
    "xx = np.linspace(2,20,100)\n",
    "yy = 2 - 2/xx\n",
    "\n",
    "ax3.errorbar(cluster_sizes, mean_densities, yerr=std_densities, fmt='-o', ms = 5, \n",
    "             ecolor='k', color = 'y', markeredgecolor = 'k', capsize = 3, alpha = 0.7)\n",
    "ax3.plot(xx,yy,'k--', alpha = 0.5, label = r'$2-2/k$')\n",
    "\n",
    "ax3.fill_between(cluster_sizes, mean_densities  + std_densities, mean_densities  - std_densities, color = \"y\",\n",
    "                 alpha = 0.3, linestyle = '--', linewidth = 2)\n",
    "\n",
    "ax3.set_xlabel('cluster size')\n",
    "ax3.set_ylabel('neighbour density')\n",
    "#ax3.grid(alpha = 0.2, linewidth = 1.);\n",
    "ax3.set_xticks([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]);\n",
    "ax3.set_xticklabels(['','', '2', '', '4', '', '6', '', '8','', '10','', '12','','14',''])\n",
    "\n",
    "ax3.set_xlim(2,14.5)\n",
    "ax3.set_ylim(1,3)\n",
    "#ax3.legend(loc = 'upper right', fontsize = 12)\n",
    "\n",
    "ax3.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "#########\n",
    "\n",
    "sizes_of_interest = [3, 4, 5]\n",
    "\n",
    "# Mapping of neighbor densities to labels (I, II, III, IV)\n",
    "density_to_label = {\n",
    "    1.33: 'I',\n",
    "    1.50: 'I',\n",
    "    1.60: 'I',\n",
    "    2.00: 'II',\n",
    "    2.40: 'III',\n",
    "    2.50: 'III',\n",
    "    2.80: 'IV',\n",
    "}\n",
    "\n",
    "# # Normalize the color map to the maximum number of labels\n",
    "# labels = ['1', '2', '3', '4']\n",
    "# cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"silver\",\"lightseagreen\"])\n",
    "# colors = cmap(np.linspace(0, 1, len(labels)))\n",
    "# label_to_color = dict(zip(labels, colors))\n",
    "\n",
    "# TC = {}\n",
    "# ss = -1\n",
    "# for size in sizes_of_interest:\n",
    "#     ss = ss + 1\n",
    "#     densities = size_density_data[size]\n",
    "    \n",
    "#     # Count occurrences of each unique density\n",
    "#     density_counts = Counter(densities)\n",
    "\n",
    "#     densities = sorted(set(density_counts.keys()))\n",
    "#     density_to_label = {density: f'{i+1}' for i, density in enumerate(densities)}\n",
    "#     transformed_counter = Counter({density_to_label[density]: count for density, count in density_counts.items()})\n",
    "\n",
    "#     # Prepare labels and sizes for the pie chart\n",
    "#     pie_labels = list(transformed_counter.keys())\n",
    "#     sizes = list(density_counts.values())\n",
    "\n",
    "#     TC[ss] = transformed_counter\n",
    "\n",
    "\n",
    "# for i, size in enumerate(sizes_of_interest):\n",
    "#     transformed_counter = TC[i]\n",
    "    \n",
    "#     # Extract and sort the sizes and corresponding labels\n",
    "#     pie_labels = list(transformed_counter.keys())\n",
    "#     sizes = [transformed_counter[label] for label in pie_labels]\n",
    "\n",
    "#     # Sort labels and sizes based on sizes in descending order\n",
    "#     sorted_indices = np.argsort(sizes)[::-1]\n",
    "#     sorted_labels = [pie_labels[i] for i in sorted_indices]\n",
    "#     sorted_sizes = [sizes[i] for i in sorted_indices]\n",
    "#     sorted_colors = [label_to_color[label] for label in sorted_labels]\n",
    "    \n",
    "#     # Create an inset axes at the x position corresponding to the cluster size\n",
    "#     inset_ax = ax3.inset_axes([size/4.4 - 0.68, 0.65, 0.3, 0.3])  # Adjust position and size\n",
    "#     wedges, texts = inset_ax.pie(sorted_sizes, startangle=90, colors=sorted_colors, \n",
    "#                                  wedgeprops={\"edgecolor\": \"black\", 'linewidth': 1, 'antialiased': True})\n",
    "    \n",
    "#     inset_ax.axis('equal')\n",
    "#     inset_ax.set_title(f'$k={size}$', y=0.9, fontsize=9)\n",
    "\n",
    "# # Add a legend with labels corresponding to the types\n",
    "# handles = [plt.Line2D([0], [0], color=label_to_color[label], lw=4) for label in labels]\n",
    "# inset_ax.legend(bbox_to_anchor=(0.9, 0.65, 0.5, 0.5), labels=['I','II','III','IV'], fontsize = 8)\n",
    "\n",
    "plt.savefig('histogram_cell_distance.pdf', transparent = True, bbox_inches='tight' )\n",
    "plt.savefig('histogram_cell_distance.svg')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95f3152-3a50-420e-ac60-d8a08a32ecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "prop_1cluster = [values.count(1) / len(values) for values in CS.values()]\n",
    "\n",
    "print(len(prop_1cluster))\n",
    "print(list(MORAN.values()))\n",
    "\n",
    "fig,(ax1,ax2) = plt.subplots(1,2,figsize = (6.,2.))\n",
    "fig.subplots_adjust(wspace=0.35)\n",
    "\n",
    "ax1.spines[['right', 'top']].set_visible(False)\n",
    "ax2.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "#ax.scatter(list(DENSITY_DARK.values()),prop_1cluster)\n",
    "\n",
    "#ax.scatter(list(MORAN.values()),list(ORDER.values()))\n",
    "\n",
    "#ax.scatter(list(DENSITY_DARK.values()),list(MORAN.values()))\n",
    "\n",
    "x = np.array(list(MORAN.values()))\n",
    "y = np.array(prop_1cluster)\n",
    "\n",
    "points = np.column_stack((x, y))\n",
    "hull = ConvexHull(points)\n",
    "\n",
    "hull_points = points[hull.vertices]\n",
    "\n",
    "ax1.boxplot(list(MORAN.values()), positions=[0.5], widths = 0.05, vert = False, showfliers = False)\n",
    "ax1.boxplot(prop_1cluster, positions=[0.15], widths = 0.015, showfliers = False)\n",
    "\n",
    "ax1.fill(hull_points[:, 0], hull_points[:, 1], color='y', alpha=0.5, linewidth = 0)\n",
    "ax1.scatter(x, y, color='y', s=18, alpha=0.5, linewidth = 0.5)\n",
    "\n",
    "ax1.set_xlim(-0.05,0.05)\n",
    "ax1.set_ylim(0.6,1.05)\n",
    "\n",
    "ax1.set_yticks([0.6,0.8,1])\n",
    "ax1.set_yticklabels([0.6,0.8,1])\n",
    "\n",
    "ax1.set_xticks([-0.05,0,0.05])\n",
    "ax1.set_xticklabels([-0.05,0,0.05])\n",
    "\n",
    "ax1.set_xlabel(\"Moran's $I$\")\n",
    "ax1.set_ylabel(\"idioblast proportion\")\n",
    "\n",
    "# plt.scatter(prop_1cluster,list(ORDER.values()))\n",
    "\n",
    "#plt.hist(density_dark.values(), bins = 10)\n",
    "\n",
    "\n",
    "WL_mean = np.array([np.mean(i) for i in LSP.values()])\n",
    "WL_std = np.array([np.std(i) for i in LSP.values()])\n",
    "\n",
    "WL_CV = WL_std/WL_mean\n",
    "\n",
    "points = np.column_stack((WL_mean, WL_CV))\n",
    "hull = ConvexHull(points)\n",
    "\n",
    "hull_points = points[hull.vertices]\n",
    "\n",
    "ax2.boxplot(WL_mean, positions=[0.3], widths = 0.07, vert = False, showfliers = False)\n",
    "ax2.boxplot(WL_CV, positions=[6.7], widths = 0.4, showfliers = False)\n",
    "\n",
    "ax2.fill(hull_points[:, 0], hull_points[:, 1], color='y', alpha=0.5, linewidth = 0)\n",
    "ax2.scatter(WL_mean,WL_CV, color='y', s=18, alpha=0.5, linewidth = 0.5)\n",
    "\n",
    "ax2.set_xlim(3,7)\n",
    "ax2.set_ylim(0.1,0.7)\n",
    "\n",
    "ax2.set_yticks([0.1,0.2,0.3,0.4,0.5,0.6,0.7])\n",
    "ax2.set_yticklabels([0.1,0.2,0.3,0.4,0.5,0.6,0.7])\n",
    "\n",
    "ax2.set_xticks([3,4,5,6,7])\n",
    "ax2.set_xticklabels([3,4,5,6,7])\n",
    "\n",
    "ax2.set_xlabel(\"average oil body cell distances $\\lambda$\")\n",
    "ax2.set_ylabel(\"CV$_\\lambda$\")\n",
    "\n",
    "plt.savefig('scatter_properties_marchantia_exp.pdf', transparent = True, bbox_inches='tight' )\n",
    "\n",
    "\n",
    "print(np.mean(list(Ncells.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6790a2f-a002-441c-8f45-ed97394bd1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "np.save(\"exp_marchantia_density.npy\", list(density_dark.values()))\n",
    "np.save(\"exp_marchantia_moran.npy\", list(MORAN.values()))\n",
    "\n",
    "with open(\"CS_marchantia_exp.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Key\", \"Value\"])  # Header\n",
    "    for k, v in CS.items():\n",
    "        writer.writerow([k, \",\".join(map(str, v))])  # Convert the list to a comma-separated string\n",
    "\n",
    "with open(\"ND_marchantia_exp.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Key\", \"Values\"])  # Header\n",
    "    for key, values in ND.items():\n",
    "        writer.writerow([key] + values)\n",
    "\n",
    "with open(\"LSP_marchantia_exp.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Key\", \"Array\"])  # Header\n",
    "    for k, v in LSP.items():\n",
    "        writer.writerow([k, \",\".join(map(str, v))])  # Convert array to comma-separated string\n",
    "\n",
    "with open(\"CSD_marchantia_exp.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Key\", \"InnerKey\", \"Value\"])  # Header\n",
    "    for outer_key, inner_dict in CSD.items():\n",
    "        for inner_key, value in inner_dict.items():\n",
    "            writer.writerow([outer_key, inner_key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337250a4-8377-4d87-9d27-88c721cf7ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
